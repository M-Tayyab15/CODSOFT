Task 1 of Machine Learning Internship.
Completed through using GoogleColab.

Step by Step Explaination:
Importing Libraries: The necessary libraries such as numpy, pandas, matplotlib, seaborn, re, nltk, sklearn, etc., are imported.

Loading Data: The data files are loaded using the provided file paths for train, test, and test solution data.

Data Preprocessing:
The train and test data DataFrames are created by reading the text files with proper delimiters and column names.
The 'Genre' column in the training data is encoded using LabelEncoder to convert genre names into numerical labels.
A bar plot is created to show the distribution of different genres in the training data.

Feature Extraction:
The 'Description' column in the training data is preprocessed using various text cleaning steps.
The Lemmatization process is applied using the NLTK library.
TF-IDF vectorization is applied to convert the processed descriptions into numerical features.
Features are extracted from the descriptions using the extract_features function, which returns the features matrix and feature names.

Train-Test Split:
The data is split into training and testing sets using train_test_split from sklearn.
Model Building and Training:
A Multinomial Naive Bayes model is created using MultinomialNB().
The model is trained using the training data features and corresponding genre labels.

Prediction and Evaluation:
The trained model is used to predict genre labels for the testing data features.
A confusion matrix is generated to show the predicted vs. actual genre labels.
The accuracy of the model is calculated using the accuracy_score function.

Summary:
The code performs the following steps:
Loads the data and preprocesses it.
Extracts features from descriptions using TF-IDF vectorization and Lemmatization.
Splits the data into training and testing sets.
Builds a Multinomial Naive Bayes model and trains it.
Predicts genre labels for the testing set and evaluates accuracy using a confusion matrix.
Overall, the code demonstrates how to preprocess text data, extract features, build a simple classification model, and evaluate its performance using the Naive Bayes algorithm. The model achieves an accuracy of approximately 52.5% on the provided dataset.
